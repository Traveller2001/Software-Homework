## 一、PSP表
作业Github链接：https://github.com/1920570209/Software-Homework/upload/mywork
![在这里插入图片描述](https://img-blog.csdnimg.cn/e6eba0bacc9a4570bad5a5c199c87521.png)
psp表链接：https://userblink.csdnimg.cn/00fa8a53104b4259940bf446faeb9a76.png
## 二、任务要求的实现
(3.1)项目设计与技术栈
1、学习python（安装python、PyCharm，学习python的语法，爬虫代码、可视化的学习）
2、编写、调试、运行代码----requests，re，json
3、导出表格，数据整理----xlsxwriter
4、性能优化，功能改进----cProfile
5、可视化操作----pandas，matplotlib
(3.2)爬虫与数据处理
爬取的网站（https://voice.baidu.com/act/newpneumonia/newpneumonia/?from=osari_aladin_banner）
```python
import requests
import re
import json
import xlsxwriter
#要爬取的网站
url='https://voice.baidu.com/act/newpneumonia/newpneumonia/?from=osari_aladin_banner'
#进行伪装
headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36 Edg/105.0.1343.33'
}
#发送请求
response = requests.get(url=url, headers=headers)
#获取数据
html_data = response.text
#解析数据
json_str = re.findall('"component":\[(.*)\],',html_data)[0]#正则表达式
json_dict = json.loads(json_str)
summaryDataIn = json_dict['summaryDataIn']
print(summaryDataIn['unOverseasInputNewAdd']) #新增本土确诊
print(summaryDataIn['asymptomaticLocalRelative']) #新增本土无症状
print(summaryDataIn['specialAdministrativeRegionRelative'])#港澳台新增
caseList = json_dict['caseList']
#保存数据，放入excel文件中
i=1
workbook = xlsxwriter.Workbook('数据统计.xlsx') # 创建一个excel文件
worksheet = workbook.add_worksheet('')  #创建工作表
#编辑excel表格
worksheet.write(0, 0, '省份')
worksheet.write(0, 1, '新增本土')
worksheet.write(0, 2, '新增本土无症状')
worksheet.write(0, 3, '大陆新增本土')
worksheet.write(0, 4, '大陆新增本土无症状')
worksheet.write(0, 5, '港澳台新增')
worksheet.write(1, 3, summaryDataIn['unOverseasInputNewAdd'])
worksheet.write(1, 4, summaryDataIn['asymptomaticLocalRelative'])
worksheet.write(1, 5, summaryDataIn['specialAdministrativeRegionRelative'])
for case in caseList:
    area = case['area']
    nativeRelative = case['nativeRelative']
    asymptomaticLocalRelative = case['asymptomaticLocalRelative']
    print(area, nativeRelative,asymptomaticLocalRelative )
    #通过循环，导入到excel表格中
    worksheet.write(i, 0, area)
    worksheet.write(i, 1, nativeRelative)
    worksheet.write(i, 2, asymptomaticLocalRelative)
    i = i + 1
workbook.close()
```
分为四个步骤：
1、发送请求
2、获取数据
3、解析数据
4、保存数据
先用request对网站进行爬取，得到数据后，利用正则表达式和json对数据进行解析，从中挑选出符合我们需求的数据，最后，调用xlsxwriter库，将爬得的数据导入excel表格中。
(3.3)数据统计接口部分的性能改进
利用cProfile对程序的每个函数的运行时间进行分析，其中，_find_and_load 函数所用到的时间最长，使用cProfile所得的每个函数所使用的时间保存于压缩包中。
(3.4)每日热点的实现思路（这个真心不会，呜呜）
(3.5)数据可视化界面的展示
使用matplotlib库调用函数来绘制表格，将提取出来的excel表中的数据导入，利用函数对柱状图的x，y轴进行编辑，再经过一些处理，将数据以柱形图的形式展现出来。绘制的结果保存于压缩包中。

```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
plt.rcParams['font.sans-serif']=['SimHei']
数据 = pd.read_excel(r"C:\Users\long'er\Desktop\032002215赖伟龙\2022.9.18疫情数据.xlsx")
x=np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33])
y1=数据['新增本土']
y2=数据['新增本土无症状']
bar_width=0.2
#设置x，y轴的标签
plt.xlabel("省份")
plt.ylabel("人数")
plt.legend()
#设置标题
plt.title("2022.9.18疫情数据",fontsize=16,fontweight='bold')
#绘制柱状图
plt.bar(x,y1,bar_width,color='c',alpha=0.5)
plt.bar(x+bar_width,y2,bar_width,color='b',alpha=0.5)
#设置坐标刻度
data=数据['省份']
plt.xticks(x,data)
#添加文本标签
for a,b in zip(x,y1):
    plt.text(a,b,format(b,','),ha='center',va='bottom',fontsize=8)
for a,b in zip(x,y2):
    plt.text(a+bar_width,b,format(b,','),ha='center',va='bottom',fontsize=8)
#设置图例
plt.legend(['新增本土','新增本土无症状'])
plt.show()
```

## 三、心得体会
本次实验难度对于我这个从没使用过python的小白来说，就如同刚学会走路就得去参加马拉松一样。我还是无法在规定时间内完成给定的任务，通过在百度和b站的学习，我对百度的https://voice.baidu.com/act/newpneumonia/newpneumonia/?from=osari_aladin_banner进行爬取，也只能爬取到当日的疫情情况。但是在经过几天几夜的奋战，虽然有时候被搞的心态炸裂，但是收获还是很大的，在百度上自学，从一穷二白到学会了python的基本用法，学会了关于爬虫的一些库，例如request、xlsxwriter、正则表达式的使用等等，还学会了柱状图的绘制，基本能够绘制出简单的图表。总之，虽然没有达到预期的要求，但是我也付出了应有的态度和努力，希望下次作业能够圆满完成！


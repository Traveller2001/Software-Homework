https://github.com/navither/Software-Homework

# 一、PSP表格

(1)
PSP2.1   |Personal Software Process Stages| 预估耗时（分钟)|实际耗时（分钟）
-------- | -----|------------- | -----
Planning| 计划| 60|90+
Estimate|  估计这个任务需要多少时间 | 10| 10
Analysis   |开发 | 1000|1500
Design Review  | 设计复审 | 30 |60+
 Design Spec  | 生成设计文档 | 10 |20
Coding Standard  | 代码规范 (为目前的开发制定合适的规范) | 10 |0
Design   | 具体设计| 60 |10
 Coding  | 具体编码 | 2000 |1145
 Code Review  | 代码复审 | 100 |514
Test  | 测试（自我测试，修改代码，提交修改）| 100 |99.8
Reporting   | 报告 | 120 |150
Test Repor   | 测试报告|  30|50
Size Measurement   | 计算工作量 | 200 |30
 Postmortem & ProcessImprovement Plan| 事后总结, 并提出过程改进计划 | 50 |80
 ||合计|3780|3608.8



# 二、任务要求的实现


*(1) 项目设计与技术栈。从阅读完题目到完成作业，这一次的任务被你拆分成了几个环节？你分别通过什么渠道、使用什么方式方法完成了各个环节？列出你完成本次任务所使用的技术栈。*

首先，由于没接触过爬虫，也不会python，故决定先去b站学一轮。
其次，学完之后，开始阅读题目，用毕生所学，尝试爬取数据。
然后，得到数据后，开始尝试处理数据导入到excel中。
最后，进行数据可视化。
	
*(2) 爬虫与数据处理。说明业务逻辑，简述代码的设计过程（例如可介绍有几个类，几个函数，他们之间的关系），并对关键的函数或算法进行说明。*

#### 1. 数据爬取：
covid.py实现数据爬取
首先我尝试了普通的request请求，但是效果很差。所以本次使用了selenium来模拟浏览器抓取数据。一开始遇到了简单的反爬，加入如下代码即可。
```
browser.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": """
            Object.defineProperty(navigator, 'webdriver', {
              get: () => undefined
            })
            """
        })
```
GetAllText函数用于找到全部数据，有时因为网页不太稳定所以可以换一个xpath但是都是获取同一数据。
```
def GetAllText():
  try:
    content = browser.find_element_by_xpath('//*[@id="xw_box"]')
    return content.text
  except NoSuchElementException:
    print("change xpath")
    content = browser.find_element_by_xpath('//div[3]/div[2]/div[3]')
    return content.text
```
#### 2. 数据处理：
ProcessData.py用于数据处理
GetDict函数使用正则表达式来获取城市以及病例数据，返回字典
```
def GetDict(str):

    cityDic = { 
    }
    
    localP = re.findall('本土病例\d{1,}例（.*），', str)
    cityP = re.findall('\w{2,}\d{1,}例', localP[0])
    
    for thing in cityP:
        cnt = 0
        for char in thing:
            if(char >= '0' and char <= '9'):
                break
            else:
                cnt += 1

        cityDic[thing[0:cnt]] = thing[cnt:len(thing)-1]

    return cityDic    
```
ReadDateOfToday函数用于打开爬取到的数据文件并生成若干天的数据。
```
def ReadDateOfToday():
    for m in range(startMonth, endMonth+1):
        for d in range(startDay, endDay):
            name = 'data\Data_2022-' + str(m).zfill(2) + '-' + str(d).zfill(2) + '.txt'         
            try:
                with open(name, 'r', encoding='utf8')as fp:
                    line = fp.readline()
                    for i in range(4):
                        upLine = fp.readline()
                    for i in range(2):
                        sLine = fp.readline()
                 
                recordedData.append('2022-' + str(m).zfill(2) + '-' + str(d).zfill(2))
                upFinalDict.append(GetUpDict(upLine))
                
                Dict = GetDict(line)
                sDic = GetSDcit(sLine)
                Dict.update(sDic)
                finalDict.append(Dict)
             
                
            except FileNotFoundError:
                print(m, d, 'No Data')
                continue

    return recordedData
```
#### 3. 数据可视化：
CreatExcel用于制作excel表格
使用如下函数
```
def CreatE(dateList):

    for date in dateList:
        columns.append(date)

    for col, column in enumerate(columns):
        sheet.write(0, col, column)

    for row, val in enumerate(provinc):
        sheet.write(row+1, 0, val)

    workbook.save('mysheet.xls')

def WriteE(cityDict, col):

    for rows in range(1, len(provinc)+1):
        print(col)
        try:
            sheet.write(rows, col, int(cityDict[col-1][provinc[rows-1]]))
            
        except KeyError:
            sheet.write(rows, col, 0)
        
    workbook.save('mysheet.xls')
```
DrawMap.py用于制作疫情地图，使用pyecharts，数据来源ProcessData.py
```

for i in range(len(dateList)):
    province_distribution = ProcessData.finalDict[i]
    provice = list(province_distribution.keys())
    values = list(province_distribution.values())
    c = (
        Map(init_opts=opts.InitOpts(width="1800", height="700px", bg_color='pink'))
        .add("", [list(z) for z in zip(provice, values)], "china")
        .set_global_opts(
            title_opts=opts.TitleOpts(title="本土每日新增确诊"),
            visualmap_opts=opts.VisualMapOpts(max_=100,is_piecewise=False,is_show=True),
            #legend_opts=opts.LegendOpts(pos_left="90%",pos_top="60%"),

            )
        
    )

    tl2.add(c, dateList[i])
    
    province_distribution = ProcessData.upFinalDict[i]
    provice = list(province_distribution.keys())
    values = list(province_distribution.values())
    c = (
        Map(init_opts=opts.InitOpts(width="1800", height="700px", bg_color='pink'))
        .add("", [list(z) for z in zip(provice, values)], "china")
        .set_global_opts(
            title_opts=opts.TitleOpts(title="本土每日新增无症状"),
            visualmap_opts=opts.VisualMapOpts(max_=100,is_piecewise=False,is_show=True),
            #legend_opts=opts.LegendOpts(pos_left="90%",pos_top="60%"),

            )
        
    )
    tl.add(c, dateList[i])

tl.add_schema(is_auto_play=True, play_interval=1000)
tl2.add_schema(is_auto_play=True, play_interval=1000)

tl.render("timeline_pie.html") 
tl2.render("upM.html") 
# 打开html
os.system("timeline_pie.html")
os.system("upM.html")
```
*(3) 数据统计接口部分的性能改进。记录在数据统计接口的性能上所花费的时间，描述你改进的思路，并展示一张性能分析图（例如可通过VS 2019/JProfiler的性能分析工具自动生成），并展示你程序中消耗最大的函数。*

*(4. )每日热点的实现思路。简要介绍实现该功能的算法原理，可给出必要的步骤流程图、数学公式推导和核心代码实现，并简要谈谈所采用算法的优缺点与可能的改进方案。*

*(5.)数据可视化界面的展示。在博客中介绍数据可视化界面的组件和设计的思路。*

可视化展示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/c9b2d5e21bb04776a33bea67fee9b356.png)
可视化使用pyecharts，有时间轴并且随着数据不同，省份的颜色也会变化。
说到全国疫情，在说到可视化，那么答案只有一个了。代码参照上面的DrawMap

# 三、心得体会
首先通过本次作业收获蛮多的，但是由于对本次作业所用到的各种知识都是第一次接触，所以遇到了各种困难，且耗费了非常多时间。上一周基本都在学python做作业。也因此掌握了一定的python基础，脱离了python小白。也对爬虫技术有了入门了解。
但是困于时间问题，加上本次作业对我自己来说难度是挺大的，最后的成品并不好也不完善，算是一个遗憾。

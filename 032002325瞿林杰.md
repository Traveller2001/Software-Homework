github链接：[请点击此](https://github.com/Probelemaking/Software-Homework/tree/mywork)

#  一、PSP表格 

## **(2.1)PSP表格记录下你估计耗费时间。（3'）**

以下是我的预计花费时间：

| PSP2.1                          | Personal Software Process Stage        | 预估耗时（分钟） | 实际耗时（分钟） |
| ------------------------------- | -------------------------------------- | ---------------- | ---------------- |
| Planning                        | 计划                                   | 30               |                  |
| Estimate                        | 估计这个任务需要多少时间               | 45               |                  |
| Development                     | 开发                                   | 90               |                  |
| Analysis                        | 需求分析（包括学习新技术）             | 1000             |                  |
| Design Spec                     | 生成设计文档                           | 80               |                  |
| Design Review                   | 设计复审                               | 30               |                  |
| Coding Standard                 | 代码规范（为目前的开发制订合适的规范） | 45               |                  |
| Design                          | 具体设计                               | 50               |                  |
| Coding                          | 具体编码                               | 2400             |                  |
| Code Review                     | 代码复审                               | 300              |                  |
| Test                            | 测试（自我测试、修改代码、提交修改）   | 300              |                  |
| Reporting                       | 报告                                   | 600              |                  |
| Test Report                     | 测试报告                               | 60               |                  |
| Size Measurement                | 计算工作量                             | 45               |                  |
| Postmortem&Process  Improvement | 事后总结，并提出过程改进计划           | 45               |                  |
|                                 | 合计                                   | 4520             |                  |

## **(2.2)实际花费的时间。（3'）**

以下是各个模块实际时间：

| PSP2.1                          | Personal Software Process Stage        | 预估耗时（分钟） | 实际耗时（分钟） |
| ------------------------------- | -------------------------------------- | ---------------- | ---------------- |
| Planning                        | 计划                                   | 30               | 30               |
| Estimate                        | 估计这个任务需要多少时间               | 30               | 50               |
| Development                     | 开发                                   | 90               | 120              |
| Analysis                        | 需求分析（包括学习新技术）             | 1800             | 2000             |
| Design Spec                     | 生成设计文档                           | 80               | 30               |
| Design Review                   | 设计复审                               | 30               | 30               |
| Coding Standard                 | 代码规范（为目前的开发制订合适的规范） | 45               | 60               |
| Design                          | 具体设计                               | 50               | 60               |
| Coding                          | 具体编码                               | 1800             | 2000             |
| Code Review                     | 代码复审                               | 300              | 300              |
| Test                            | 测试（自我测试、修改代码、提交修改）   | 300              | 120              |
| Reporting                       | 报告                                   | 600              | 1000             |
| Test Report                     | 测试报告                               | 60               | 60               |
| Size Measurement                | 计算工作量                             | 45               | 30               |
| Postmortem&Process  Improvement | 事后总结，并提出过程改进计划           | 45               | 60               |
|                                 | 合计5305                               | 5305             | 5950             |

--------------------------------
# 二、任务要求的实现 
## **(3.1)项目设计与技术栈。（5'）**
- 这次任务拆成了四个环节，第一个环节为爬取子页面的url，使用了requests模块来读爬取子页面内容，再通过BeautifulSoup模块来定位子页面的url，并存入到新建的yiqing.txt文件中；第二个环节为爬取爬取子页面的内容，通过导入os模块读取了在第一个环节中提到的yiqing.txt文件，得到了子页面的具体url，由于子页面文本有js加密，无法使用requests模块来爬取文本信息，于是使用了selenium模块来模拟浏览器的手动登录，并导入pool模块，使用了线程池，最后通过xpath模块定位到所需的文本内容，并保存在当前目录的疫情详细信息的文件夹内；第三个环节通过正则表达式获取到每日新增确诊与新增无症状的各个省份的具体人数与总数。再通过调用pandas下的pd模块，将数据导入，生成了excel表格中；第四个环节，通过表格内的数据生成可视化动态大屏。在有了excel表格的基础上，调用pycharts.charts模块，画出一个月内的饼图，分布图，折线图并在一个页面内结合着显示，完成数据的可视化处理。

- 前两个环节主要还是通过了b站来系统且具体学python的语法，与相关爬虫的代码。后面的环节通过再baidu、csdn、github上查询相关的内容去学习并完成(~~拼成~~)代码。

## **(3.2)爬虫与数据处理。（20'）**

下图为与爬虫与数据处理有关的主函数部分：

![思维导图](https://s1.328888.xyz/2022/09/20/24F9P.png)

> 1.  第一个环节，设计过程是先通过requests访问到主页面的内容，再用BeautifulSoup定位到子页面的url，把爬取到的数据存放在yiqing.txt下

```python
# 爬取第一页到四十一页的每一天的url
def get_kids_links():
    for page_num in range(1, 42):
        if page_num:
            new_url = first_page  # 第一天的url
        else:
            new_url = format(next_page % page_num)  # 后面的url，通过format给%d附带上页码
        res = requests.get(url=new_url, headers=headers)  # 请求网址
        page_text = res.text                             #获取内容
        soup = BeautifulSoup(page_text, 'lxml')
        li_list = soup.select('.zxxx_list > li > a')  # 定位url部分
        while res.status_code != 200:  # 如果访问失败，就重复访问
            sleep(random.randint(0, 3) * 0.1 / 100)
            res = requests.get(url=new_url, headers=headers)    #与上述相同
            page_text = res.text
            soup = BeautifulSoup(page_text, 'lxml')
            li_list = soup.select('.zxxx_list > li > a')
        # 存入yiqing.txt文件中
        for li in li_list:
            title = li.string
            detail_url = 'http://www.nhc.gov.cn' + li['href']  # 所需要的详细网址
            fp.write(detail_url + '\n')
```
> 2. 第二个环节，通过selenium模块模拟浏览器手动登录，通过xpath定位到子页面下的文本内容信息，存入到疫情详细信息的文件夹内，由于selenium模块较慢，启动了线程池来加快访问。

```python
# 用于获取子页面的具体内容
def get_name(url):
    # 创建文件夹
    file = '疫情详细信息'
    if not os.path.exists(file):
        os.mkdir(file)
    # 显示无可视化界面，同通过selenium模块对火狐浏览器发起模拟登录
    options = Options()
    options.headless = True
    bro = webdriver.Firefox(options=options)
    bro.get(url)                #进入子页面
    page_text = bro.page_source  # 直接返回源码
    while '疫情通报' not in page_text:  # 如果访问失败，重复访问
        sleep(random.randint(0, 3) * 0.1 / 100)
        bro.get(url)        # 与上述相同
        page_text = bro.page_source
    # 内容定位
    tree = etree.HTML(page_text)    #xpath内容定位
    r = tree.xpath('//div[@class="con"]//text()')
    text_content = ''.join(r)  # 获取文本内容
    r = str(tree.xpath('//div[@class="source"]/span[1]/text()')[0])  # 获取发布时间
    release_time = r.split('发布时间：\n')[1].strip()
    title = tree.xpath('//div[@class="tit"]/text()')[0]  # 获取标题
    #保存到文件夹内
    filename = release_time + '（发布时间）' + title + '.html'  # 定义文件名
    with open(file + '/' + filename, 'w', encoding='utf8') as fp:
        fp.write(text_content)
    print(filename + "保存成功！！！")
    bro.quit()

# 启动线程池加快爬取
def create_pool(urls):
    # 创建线程池，并启动
    pool = Pool(7)
    pool.map(get_name, urls)
    pool.close()
    pool.join()
```

> 3. 第三个环节通过正则表达式获取到每日新增确诊与新增无症状的各个省份的具体人数与总数。再通过调用pandas下的pd模块，将数据导入到了excel表格中。由于正则部分代码太长且晦涩难懂（自己写的正则代码只有自己才能看懂），~~属于是一坨屎山~~，此处不放出代码，仅仅展示港澳台部分与表格生成。

```python
# 下列统计港澳台每日新增
# 匹配目标段落，如['香港特别行政区401942例（出院79100例，死亡9820例），澳门特别行政区793例（出院787例，死亡6例），台湾地区5754683例（出院13742例，死亡10329例）。']
ex = '(香港特别行政区.*)'
str2 = re.findall(ex, filecontent, re.M)
# print(str2)
yesterday_number = date_number - 1
if len(str2) != 0:
    if "香港特别行政区" in str2[0]:
        ex = '香港特别行政区(\d*)例'  # 找到香港后面感染人数
        num = re.findall(ex, str2[0])
        if len(num) != 0:
            xianggang_list.append(int(num[0]))
            province_list["香港"] += xianggang_list[date_number] - xianggang_list[
                yesterday_number]  # 今天与昨天相减即为新增

    if "澳门特别行政区" in str2[0]:
        ex = '澳门特别行政区(\d*)例'  # 找到澳门后面感染人数
        num = re.findall(ex, str2[0])
        if len(num) != 0:
            aomen_list.append(int(num[0]))
            province_list["澳门"] += aomen_list[date_number] - aomen_list[yesterday_number]  # 今天与昨天相减即为新增

    if "台湾地区" or "中国台湾" in str2[0]:
        ex = '台湾.*?(\d*)例'  # 找到台湾后面感染人数
        num = re.findall(ex, str2[0])
        if len(num) != 0:
            taiwan_list.append(int(num[0]))
            province_list["台湾"] += taiwan_list[date_number] - taiwan_list[yesterday_number]  # 今天与昨天相减即为新增
else:
    # 特例，当天发的不是平时的疫情通告，2020-04-17（发布时间）[武汉发布] 武汉市新冠肺炎确诊病例数确诊病例死亡数订正情况答记者问.html
    xianggang_list.append(int(xianggang_list[yesterday_number]))
    taiwan_list.append(int(taiwan_list[yesterday_number]))
    aomen_list.append(int(aomen_list[yesterday_number]))

time_specific = str(date_number) + '.' + date[0]  # 得到具体时间
time_city_dic[time_specific] = province_list  # 得到时间与具体信息的字典
print(str(date[0]) + '日信息录入完毕！！！')

# 创建表格
df = pd.DataFrame.from_dict(time_city_dic, orient='index')
df.to_excel('中国每日本土新增确诊人数（转置版）.xlsx')
df = df.T
df.to_excel('中国每日本土新增确诊人数.xlsx')
print("已生成中国每日本土新增确诊人数.html")
print("中国每日本土新增确诊人数已完成！！！")
```

## **(3.3)数据统计接口部分的性能改进。（6'）**

下列是接口性能花费时间：

![数据1](https://s1.328888.xyz/2022/09/20/24L6d.png)![数据2](https://s1.328888.xyz/2022/09/20/24NVU.png)

![数据3](https://s1.328888.xyz/2022/09/20/24lpB.png)![数据4](https://s1.328888.xyz/2022/09/20/24DFR.png)

![性能分析](https://s1.328888.xyz/2022/09/20/24O76.png)

改进思路：之前是使用selenium模块没有应用线程池，导致通常需要数小时才能爬取完整子页面的内容，在添加了线程池之后，爬取时间缩短到23分钟，换来的代价是线程锁，与过高的cpu占用率。

消耗最大的函数：

```python
# 用于获取子页面的具体内容
def get_name(url):
    # 创建文件夹
    file = '疫情详细信息'
    if not os.path.exists(file):
        os.mkdir(file)
    # 显示无可视化界面，同通过selenium模块对火狐浏览器发起模拟登录
    options = Options()
    options.headless = True
    bro = webdriver.Firefox(options=options)
    bro.get(url)                # 进入子页面
    page_text = bro.page_source  # 直接返回源码
    while '疫情通报' not in page_text:  # 如果访问失败，重复访问
        sleep(random.randint(0, 3) * 0.1 / 100)
        bro.get(url)        # 与上述相同
        page_text = bro.page_source

    # 内容定位
    tree = etree.HTML(page_text)    # xpath内容定位
    r = tree.xpath('//div[@class="con"]//text()')
    text_content = ''.join(r)  # 获取文本内容
    r = str(tree.xpath('//div[@class="source"]/span[1]/text()')[0])  # 获取发布时间
    release_time = r.split('发布时间：\n')[1].strip()
    title = tree.xpath('//div[@class="tit"]/text()')[0]  # 获取标题

    # 保存到文件夹内
    filename = release_time + '（发布时间）' + title + '.html'  # 定义文件名
    with open(file + '/' + filename, 'w', encoding='utf8') as fp:
        fp.write(text_content)
    print(filename + "保存成功！！！")
    bro.quit()


# 启动线程池加快爬取
def create_pool(urls):
    # 创建线程池，并启动
    pool = Pool(7)
    pool.map(get_name, urls)
    pool.close()
    pool.join()
    print("已生成疫情详细信息文件夹！！！")
    print("所有数据爬取完成！！！")
```

## **(3.4)每日热点的实现思路。（6'）**

实现思路：通过提取目标文本，**手肘法选择聚类中心数**对所需的文本进行聚类挖掘，找出热点问题,由于时间问题，后续的有些步骤暂时未完成。

> 1. 文本内容获取，读取文本内数据，参考模块二，读取子页面详细信息。

```python
def get_urls():
    # 读取文件并保存
    f = open("yiqing.txt", "r", encoding='utf-8')
    urls = f.readlines()
    for i in range(len(urls)):  # 读取每一天的url
        urls[i] = urls[i].rstrip('\n')
    return urls


# 用于获取子页面的具体内容
def get_name(url):
    # 创建文件夹
    file = '疫情详细信息'
    if not os.path.exists(file):
        os.mkdir(file)
    # 显示无可视化界面，同通过selenium模块对火狐浏览器发起模拟登录
    options = Options()
    options.headless = True
    bro = webdriver.Firefox(options=options)
    bro.get(url)                # 进入子页面
    page_text = bro.page_source  # 直接返回源码
    while '疫情通报' not in page_text:  # 如果访问失败，重复访问
        sleep(random.randint(0, 3) * 0.1 / 100)
        bro.get(url)        # 与上述相同
        page_text = bro.page_source

    # 内容定位
    tree = etree.HTML(page_text)    # xpath内容定位
    r = tree.xpath('//div[@class="con"]//text()')
    text_content = ''.join(r)  # 获取文本内容
    r = str(tree.xpath('//div[@class="source"]/span[1]/text()')[0])  # 获取发布时间
    release_time = r.split('发布时间：\n')[1].strip()
    title = tree.xpath('//div[@class="tit"]/text()')[0]  # 获取标题

    # 保存到文件夹内
    filename = release_time + '（发布时间）' + title + '.html'  # 定义文件名
    with open(file + '/' + filename, 'w', encoding='utf8') as fp:
        fp.write(text_content)
    print(filename + "保存成功！！！")
    bro.quit()
```

> 2. 去除中间的停用词.[停用词链接](https://blog.csdn.net/kobeyu652453/article/details/106939559 )



```
# 定义删除除字母,数字，汉字以外的所有符号的函数
def remove_punctuation(line):
    line = str(line)
    if line.strip() == '':
        return ''
    rule = re.compile(u"[^a-zA-Z0-9\u4E00-\u9FA5]")
    line = rule.sub('', line)
    return line

#停用词
def stopwordslist(filepath):
    stopwords = [line.strip() for line in open(filepath, 'r', encoding='gbk').readlines()]
    return stopwords

```

> 3. 通过tf-idf算法获取词频率
>
>    TF-IDF（term frequency–inverse document frequency，词频-逆向文件频率）**是一种用于信息检索（information retrieval）与文本挖掘（text mining）**的常用加权技术。
>
>     TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。**字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。**
>
>     TF-IDF的主要思想是：如果某个单词在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。
>
>    ![image-20220919202810613](https://s1.328888.xyz/2022/09/20/20RzS.png)
>
>    ![image-20220919202818890](https://img-blog.csdn.net/20180807191126207?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FzaWFsZWVfYmlyZA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

> 4. 手肘法选择聚类中心数
>
> 手肘法的核心指标是SSE(sum of the squared errors，误差平方和)，
>
> ![20200907142231157](https://s1.328888.xyz/2022/09/20/20WGN.png)
>
> 其中，Ci是第i个簇，p是Ci中的样本点，mi是Ci的质心（Ci中所有样本的均值），SSE是所有样本的聚类误差，代表了聚类效果的好坏。
>
> 手肘法的核心思想是：随着聚类数k的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和SSE自然会逐渐变小。并且，当k小于真实聚类数时，由于k的增大会大幅增加每个簇的聚合程度，故SSE的下降幅度会很大，而当k到达真实聚类数时，再增加k所得到的聚合程度回报会迅速变小，所以SSE的下降幅度会骤减，然后随着k值的继续增大而趋于平缓，也就是说SSE和k的关系图是一个手肘的形状，而这个肘部对应的k值就是数据的真实聚类数。当然，这也是该方法被称为手肘法的原因。

> 5. 类聚实现与结果汇总，绘制高频词词云图。

> 该算法的优缺点：代码主要通过jieba实现TF-IDF算法，TF-IDF算法的优点是简单快速，结果比较符合实际情况。但他的缺点也很明显，TF-IDF 采用文本逆频率 IDF 对 TF 值加权取权值大的作为关键词，但 IDF  的简单结构并不能有效地反映单词的重要程度和特征词的分布情况，使其无法很好地完成对权值调整的功能，所以 TF-IDF  算法的精度并不是很高，尤其是当文本集已经分类的情况下。
>
> 

## **(3.5)数据可视化界面的展示。（15'）**  

- 以下是数据可视化界面的展示：

  整个画面由地区分布图，饼图，折线图，柱状图组成，画面每五秒改变一次。其中地区分布图根据左上角的感染人数对应颜色将地图划分成不同的颜色。左下角的柱状图，与右下饼图角的详细的显示了各个地区的感染人数。而折线图则是反应当前一个月的感染人数的趋势。

  ![动画3](https://s1.328888.xyz/2022/09/20/20d8y.gif)

  ![动画](https://s1.328888.xyz/2022/09/20/20vRC.gif)

  

- 设计的总体思路就是将用pyecharts.charts模块的强大功能进行表格的绘制，通过其下的grid的并行多图使最后的结果能在一张图像上显示地区分布图，饼图，折线图，最后形成所需的一个月的动态数据可视化图表。因为我把每日新增患者与新增无症状的代码分开，下面以每日新增患者的代码思路为例。

  1. 在有了第三个环节得到的本土每日新增的无症状表格的前提下，通过pandas模块导出的数据，再通过一系列复杂的循环与组合（具体参见下列代码），形成了一个list中有dic，dic中有list，list中还有dic，dic中再有list的复杂的套娃结构。

     ```python
     # data为所需一个月的数据列表
     data = [
         {
         	#’data‘为一天所需的数据列表
             'data': [
                 {'name': '河北', 'value': [0, 0.0, '河北']},  #地区为河北，第一个0为当天疫情新增患者，0.0为当前地区当天感染人数
                 {'name': '山西', 'value': [0, 0.0, '山西']},  #占当天感染人数的比值
                 {'name': '辽宁', 'value': [0, 0.0, '辽宁']}, 
                 {'name': '吉林', 'value': [0, 0.0, '吉林']}, 
                 {'name': '黑龙江', 'value': [0, 0.0, '黑龙江']}, 
                 {'name': '江苏', 'value': [0, 0.0, '江苏']}, 
                 {'name': '浙江', 'value': [0, 0.0, '浙江']}, 
                 {'name': '安徽', 'value': [0, 0.0, '安徽']}, 
                 {'name': '福建', 'value': [0, 0.0, '福建']}, 
                 {'name': '江西', 'value': [0, 0.0, '江西']}, 
                 {'name': '山东', 'value': [0, 0.0, '山东']}, 
                 {'name': '河南', 'value': [0, 0.0, '河南']}, 
                 {'name': '湖北', 'value': [0, 0.0, '湖北']}, 
                 {'name': '湖南', 'value': [0, 0.0, '湖南']}, 
                 {'name': '广东', 'value': [0, 0.0, '广东']}, 
                 {'name': '海南', 'value': [0, 0.0, '海南']}, 
                 {'name': '四川', 'value': [0, 0.0, '四川']}, 
                 {'name': '贵州', 'value': [0, 0.0, '贵州']}, 
                 {'name': '云南', 'value': [0, 0.0, '云南']},
                 {'name': '陕西', 'value': [0, 0.0, '陕西']},
                 {'name': '甘肃', 'value': [0, 0.0, '甘肃']}, 
                 {'name': '青海', 'value': [0, 0.0, '青海']}, 
                 {'name': '北京', 'value': [0, 0.0, '北京']},
                 {'name': '天津', 'value': [0, 0.0, '天津']}, 
                 {'name': '上海', 'value': [0, 0.0, '上海']}, 
                 {'name': '重庆', 'value': [0, 0.0, '重庆']}, 
                 {'name': '内蒙古', 'value': [0, 0.0, '内蒙古']},
                 {'name': '广西', 'value': [0, 0.0, '广西']}, 
                 {'name': '西藏', 'value': [0, 0.0, '西藏']},
                 {'name': '宁夏', 'value': [0, 0.0, '宁夏']}, 
                 {'name': '新疆', 'value': [0, 0.0, '新疆']}
                 ], 
             'time': '2020-01-12'	#‘time’为时间
         },
         ... #下一天
       ]
     ```

     ```python
     data = []
     date_list = []
     total_num = []
     total1_num = []
     time_list = []
     minNum=0
     maxNum=50
     maxday = 0
     minday = 0
     date = ''
     def get_data():
         file_name = '中国每日本土新增确诊人数.xlsx'
         df = pd.read_excel(file_name)
         full_time_list = df.columns
     
         file_name = '中国每日本土新增确诊人数（转置版）.xlsx'
         df = pd.read_excel(file_name)
         province_list = list[df]
         i = 0
     
         # 遍历表格中的每一天，获取对应省份信息，并形成一定的格式
         for row in df.index.values:  # 获取行号的索引，并对其进行遍历：
             # 根据row来获取每一行指定的数据 并利用to_dict转成字典
             all_province_dic = df.loc[row, ['河北', '山西', '辽宁', '吉林', '黑龙江',           '江苏', '浙江', '安徽', '福建', '江西', '山东', '河南', '湖北', '湖南', '广            东', '海南',  '四川', '贵州', '云南', '陕西', '甘肃', '青海', '北京', '天津',          '上海', '重庆', '内蒙古', '广西', '西藏', '宁夏', '新疆']].to_dict()
             all_num_list = df.loc[row, ['中国大陆（无港澳台）']].to_list()
             # print(all_num_list)
             total_num.append(all_num_list[0])
             total1_num.append(int(all_num_list[0]))
             # test_data.append(all_province_dic)
             # print(all_province_dic)
             # print(all_num_list)
             data_list = []
             # 遍历一天的每一个城市
             for city in all_province_dic.keys():  # 获得
                 each_city_dic = {}
                 each_city_dic["name"] = city
                 each_city_dic_value_list = []
                 each_city_dic_value_list.append(all_province_dic[city])
                 if (all_num_list[0] == 0):  # 被除数为0
                     num = 0.00
                 else:
                     num = all_province_dic[city] / all_num_list[0]
                 each_city_dic_value_list.append(num)
                 each_city_dic_value_list.append(city)
                 each_city_dic["value"] = each_city_dic_value_list
                 data_list.append(each_city_dic)
                 # print(each_city_dic)
             i += 1
             data_dic = {}
             data_dic["data"] = data_list
             data_dic["time"] = full_time_list[i].split('.')[1]
             data.append(data_dic)
     
         # 将得到的时间转化成list
         for num in full_time_list:
             if (num != "Unnamed: 0"):
                 time_list.append(num.split('.')[1])
         return data
     ```
  
  2. 在得到了一系列相关数据的基础上，绘制出地区分布图，饼图，折线图，再用上grid的并行多图将他们整合再一起，（此内容较多详情请[点击这里](https://pyecharts.org/#/zh-cn/composite_charts)）最后形成动态可视化大屏。
  
     ```
          #获取基础表格，一天一张表格
        def get_day_chart(day: str):
              # 获取到由data_mark生成的每日疫情总人数的list
              map_data = [
                  [[x["name"], x["value"]] for x in d["data"]] for d in data if d["time"] == day
              ][0]
              min_data, max_data = (minNum, maxNum)
              data_mark: List = []
              i = minday
              for x in time_list[minday:maxday]:
                  if x == day:
                      data_mark.append(total_num[i])
                      # print(total_num[i],' ',str(i))
                  else:
                      data_mark.append("")
                  i = i + 1
              # print(data_mark)
              # 生成地区图
              map_chart = (
                  Map()
                  .add(
                      series_name="",
                      data_pair=map_data,
                      zoom=1,
                      center=[119.5, 34.5],
                      is_map_symbol_show=False,
                      itemstyle_opts={
                          "normal": {"areaColor": "#323c48", "borderColor": "#404a59"},
                          "emphasis": {
                              "label": {"show": Timeline},
                              "areaColor": "rgba(255,255,255, 0.5)",
                          },
                      },
                  )
                  .set_global_opts(
                      title_opts=opts.TitleOpts(
                          title="" + str(day) + "中国每日本土新增确诊人数(单位:人） 数据来源：国家卫健委",
                          subtitle="",
                          pos_left="center",
                          pos_top="top",
                          title_textstyle_opts=opts.TextStyleOpts(
                              font_size=25, color="rgba(255,255,255, 0.9)"
                          ),
                      ),
                      tooltip_opts=opts.TooltipOpts(
                          is_show=True,
                          formatter=JsCode(
                              """function(params) {
                              if ('value' in params.data) {
                                  return params.data.value[2] + ': ' + params.data.value[0];
                              }
                          }"""
                          ),
                      ),
                      visualmap_opts=opts.VisualMapOpts(
                          is_calculable=True,
                          dimension=0,
                          pos_left="30",
                          pos_top="center",
                          range_text=["High", "Low"],
                          range_color=["lightskyblue", "yellow", "orangered"],
                          textstyle_opts=opts.TextStyleOpts(color="#ddd"),
                          min_=min_data,
                          max_=max_data,
                      ),
                  )
              )
          
              # 绘制折线图
              line_chart = (
          
                  Line()
                  .add_xaxis(time_list[minday:maxday])
                  .add_yaxis("", total1_num[minday:maxday])
                  .add_yaxis(
                      "",
                      data_mark,
                      markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_="max")]),
                  )
                  .set_series_opts(label_opts=opts.LabelOpts(is_show=False))
                  .set_global_opts(
                      title_opts=opts.TitleOpts(
                          title="中国当月本土新增确诊人数(单位:人）", pos_left="72%", pos_top="5%"
                      )
                  )
              )
              bar_x_data = [x[0] for x in map_data]
              bar_y_data = [{"name": x[0], "value": x[1][0]} for x in map_data]
              bar = (
                  Bar()
                  .add_xaxis(xaxis_data=bar_x_data)
                  .add_yaxis(
                      series_name="",
                      y_axis=bar_y_data,
                      label_opts=opts.LabelOpts(
                          # is_show=True, position="right", formatter="{b} : {c}"
                          is_show=True, position="right%", formatter="{b} : {c}"
                      ),
                  )
                  .reversal_axis()
                  .set_global_opts(
                      xaxis_opts=opts.AxisOpts(
                          max_=maxNum, axislabel_opts=opts.LabelOpts(is_show=False)
                      ),
                      yaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(is_show=False)),
                      tooltip_opts=opts.TooltipOpts(is_show=False),
                      visualmap_opts=opts.VisualMapOpts(
                          is_calculable=True,
                          dimension=0,
                          pos_left="10",
                          pos_top="top",
                          range_text=["High", "Low"],
                          range_color=["lightskyblue", "yellow", "orangered"],
                          textstyle_opts=opts.TextStyleOpts(color="#ddd"),
                          min_=min_data,
                          max_=max_data,
                      ),
                  )
              )
          
              # 绘制饼图
              pie_data = [[x[0], x[1][0]] for x in map_data]
              pie = (
                  Pie()
                  .add(
                      series_name="",
                      data_pair=pie_data,
                      radius=["15%", "35%"],
                      center=["80%", "82%"],
                      itemstyle_opts=opts.ItemStyleOpts(
                          border_width=1, border_color="rgba(0,0,0,0.3)"
                      ),
                  )
                  .set_global_opts(
                      tooltip_opts=opts.TooltipOpts(is_show=True, formatter="{b} {d}%"),
                      legend_opts=opts.LegendOpts(is_show=False),
                  )
              )
          
              # 绘制综合图
              grid_chart = (
                  Grid()
                  .add(
                      bar,
                      grid_opts=opts.GridOpts(
                          pos_left="10", pos_right="45%", pos_top="50%", pos_bottom="5"
          
                      ),
                  )
                  .add(
                      line_chart,
                      grid_opts=opts.GridOpts(
                          pos_left="65%", pos_right="80", pos_top="10%", pos_bottom="50%"
                      ),
                  )
                  .add(pie, grid_opts=opts.GridOpts(pos_left="45%", pos_top="60%"))
                  .add(map_chart, grid_opts=opts.GridOpts())
              )
              # print(map_data[0])
          
              # print(type(total_num[885]))
              return grid_chart
     ```
  
     



----------------------------------
# 三、心得体会  



##  (4.1)在这儿写下你完成本次作业的心得体会。（10'）

- 由于此前没有用过python语言，所以可以说这次的作业是真0基础，从最开始的pycharm安装，到最后可视化图表的完成。在这两周（~~其实就一周~~）时间内学习了许多的知识，经历也可以说是十分曲折。

- 最大的感受就是要合理分配时间吧。其实最开始并没有想到这次的软工作业会有这么大的工作量（~~尤其是对一位小白来说，也算是还下大一大二的债~~），一开始抱着突击两天就能写完了的态度，结果当我开始学python语法和爬虫基础的时候，我就意识到了不对劲。这个东西突击两天应该是写不完，于是开始了漫长而又枯燥的学习之路。如果上天再给我一次机会，我会在9月12号下午14：00时，关闭英雄联盟，而不是打英雄联盟的战斗之夜到凌晨。

- 其次，就是意识到快速学习的能力很重要。在第三个环节正则爬取相关数据时，由浅入深十分详细地学习正则表达式的相关语法内容。但是在实际使用过程中，其实并没有用到那么多的内容，但是却花费了挺多的时间，也算是学习的一种不确定性。selenium模块的学习中也是如此，并没有使用到后续的鼠标模拟点击的部分。还有就是在一些理应快速实现的地方花费了过多的时间，也算是这次作业的深刻体会。

- 再次，动手解决问题的能力还不够，也就是查找资料不够精准。在编程过程中充满了不确定性，最怕的就是就是运行时一大堆奇奇怪怪报错信息，直接让你无从下手。有的时候理解不了报错信息，网络上查找问题的答案也回答不到点子上。

- 至于本次的创新，或许就是可视化模块的部分，使用了pyecharts.charts模块的强大功能进行表格的绘制，通过其下的grid的并行多图使最后的结果能在一张图像上显示地区分布图，饼图，折线图，最后形成所需的一个月的动态数据可视化图表。

- 个人认为，这次作业量较大，而且较难，投入了大量的时间成本，难以分配其他学科的学习。但最后也算是完成了任务要求。还有就是球球下次的结对作业能延长一点时间，人都学麻了。

  


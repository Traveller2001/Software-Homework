**github仓库：**https://github.com/wangxintao2002/022000626.git


# 一、PSP表格

| **PSP2.1**                               | **Personal Software             Process Stages** | 预计耗时 （分钟） | 实际耗时（分钟） |
| ---------------------------------------- | ------------------------------------------------ | ----------------- | ---------------- |
| Planning                                 | 计划                                             | 80                | 100              |
| · Estimate                               | · 估计这个任务需要多少时间                       | 1200              | 1000             |
| Development                              | 开发                                             | 720               | 600              |
| · Analysis                               | · 需求分析 (包括学习新技术)                      | 300               | 300              |
| · Design Spec                            | · 生成设计文档                                   | 60                | 60               |
| · Design Review                          | · 设计复审                                       | 60                | 60               |
| · Coding Standard                        | · 代码规范 (为目前的开发制定合适的规范)          | 60                | 60               |
| · Design                                 | · 具体设计                                       | 60                | 60               |
| · Coding                                 | · 具体编码                                       | 60                | 60               |
| · Code Review                            | · 代码复审                                       | 60                | 60               |
| · Test                                   | · 测试（自我测试，修改代码，提交修改）           | 60                | 60               |
| Reporting                                | 报告                                             | 100               | 100              |
| · Test Repor                             | · 测试报告                                       | 60                | 60               |
| · Size Measurement                       | · 计算工作量                                     | 60                | 60               |
| ·  Postmortem & Process Improvement Plan | · 事后总结, 并提出过程改进计划                   | 60                | 60               |
|                                          | · 合计                                           | 5000              | 4700             |

# 二、任务要求的实现



## 2.1 项目与技术栈

### 项目流程分析

- 1.发送请求,获取疫情首页
- 2.对爬取到的数据进行处理
- 3.从疫情首页中提取疫情相关数据

### **技术栈**

**python**（**pyppeteer**模块、**asyncio**模块、**os**模块、**re**模块、**openpyxl**模块）



## 2.2 爬虫与数据处理

### **需求分析**

统计中国大陆每日本土新增确诊病例以及新增新增无症状感染病例。

### 实现过程

#### 编写代码实现爬虫

- 使用selenium爬取国家卫健委疫情数据

```
from selenium.webdriver import Firefox
from selenium.webdriver import FirefoxOptions
import time,re
from pyppeteer import launch
import os
from multiprocessing import Pool
import requests
import json
from fake_useragent import UserAgent
```


#累计确诊（tx已有）
```
all_dict['confirm_all'] = re.search('据31个省（自治区、直辖市）和新疆生产建设兵团.*?累计报告确诊病例(.*?)例，',news).group(1)
```
#现有确诊
```
all_dict['confirm_now'] = re.search('据31个省（自治区、直辖市）和新疆生产建设兵团报告，现有确诊病例(.*?)例.*?，',news).group(1)
```
#新增确诊
```
all_dict['confirm_add'] = re.search('31个省（自治区、直辖市）和新疆生产建设兵团报告新增确诊病例(.*?)例，',news).group(1)
```
#现有疑似（tx已有）
```
all_dict['suspect_now'] = re.search('据31个省（自治区、直辖市）和新疆生产建设兵团.*?现有疑似病例(.*?)例。',news).group(1)
```
#新增疑似
```
all_dict['suspect_add'] = re.search('31个省（自治区、直辖市）和新疆生产建设兵团报告新增确诊病例.*?新增疑似病例(.*?)例，',news).group(1)
```
#累计死亡（tx已有）
```
all_dict['dead_all'] = re.search('据31个省（自治区、直辖市）和新疆生产建设兵团.*?累计死亡病例(.*?)例',news).group(1)
```
#新增死亡
```
all_dict['dead_add'] = re.search('31个省（自治区、直辖市）和新疆生产建设兵团报告新增确诊病例.*?新增死亡病例(.*?)',news).group(1)  #???
```
#累计治愈（tx已有）
```
all_dict['heal_all'] = re.search('据31个省（自治区、直辖市）和新疆生产建设兵团.*?累计治愈出院病例(.*?)例',news).group(1)
```
#新增治愈
```
all_dict['heal_new'] = re.search('当日新增治愈出院病例(.*?)例',news).group(1)
```



#香港
#香港累计确诊
```
gat_dict['hk_confirm_all'] = re.search('香港特别行政区(\d+)例', news).group(1)
```
#香港出院
```
gat_dict['hk_heal_all'] = re.search('香港特别行政区.*?出院(\d+)例', news).group(1)
```
#香港死亡
```
gat_dict['hk_dead_all'] = re.search('香港特别行政区.*?死亡(.*?)例）', news).group(1)
```
# 香港现有确诊
```
gat_dict['hk_confirm_now'] = int(gat_dict['hk_confirm_all']) - int(gat_dict['hk_heal_all']) - int(gat_dict['hk_dead_all'])
```
#澳门
#澳门累计确诊
```
gat_dict['om_confirm_all'] = re.search('澳门特别行政区(\d+)例', news).group(1)
```
#澳门出院
```
gat_dict['om_heal_all'] = re.search('澳门特别行政区.*?出院(.*?)例）', news).group(1)
```
# 澳门现有确诊
```
gat_dict['om_confirm_now'] = int(gat_dict['om_confirm_all']) - int(gat_dict['om_heal_all'])
```
#台湾
#台湾累计确诊
```
gat_dict['tw_confirm_all'] = re.search('台湾地区(\d+)例',news).group(1)
```
#台湾出院
```
gat_dict['tw_heal_all'] = re.search('台湾地区.*?出院(.*?)例.*?死亡',news).group(1)
```
# 台湾死亡
```
gat_dict['tw_dead_all'] = re.search('台湾地区.*?死亡(.*?)例）',news).group(1)
```
# 台湾现有确诊
```
gat_dict['tw_confirm_now'] = int(gat_dict['tw_confirm_all']) - int(gat_dict['tw_heal_all']) - int(gat_dict['tw_dead_all'])
```
#港澳台累计确诊
```
gat_dict['got_confirm_all'] = re.search('累计收到港澳台地区通报确诊病例(.*?)例。', news).group(1)
```
# 港澳台现有确诊
```
gat_dict['got_confirm_now'] = int(gat_dict['tw_confirm_now']) + int(gat_dict['hk_confirm_now']) + int(gat_dict['om_confirm_now'])
```
# 港澳台累计治愈
```
gat_dict['got_heal_all'] = int(gat_dict['hk_heal_all']) +int(gat_dict['om_heal_all']) +int(gat_dict['tw_heal_all'])
```
# 港澳台累计死亡
```
gat_dict['got_dead_all'] = int(gat_dict['hk_dead_all']) + int(gat_dict['tw_dead_all'])
```

#全国总数（含港澳台）
# 全国总累计确诊
```
ch_all_dict['ch_confirm_all'] = int(all_dict['confirm_all']) + int(gat_dict['got_confirm_all'])
```
# 全国总现有确诊
```
ch_all_dict['ch_confirm_now'] = int(all_dict['confirm_now']) + int(gat_dict['got_confirm_now'])
```
# 全国总累计治愈
```
ch_all_dict['ch_heal_all'] = int(all_dict['heal_all']) + int(gat_dict['got_heal_all'])
```
# 全国总累计死亡
```
ch_all_dict['ch_dead_all'] = int(all_dict['dead_all']) + int(gat_dict['got_dead_all'])
```
for k,v in ch_all_dict.items():
    print(k,v)

```
	def dxy_data_down(article_url)
    url = urlopen(article_url)
    soup = BeautifulSoup(url, 'html.parser')

    f = open("疫情数据.txt", "w", encoding="utf-8")
    f.write(str(soup))
    f.close()



json_start = "try { window.getAreaStat = "
```
json_end = "}catch\(e\){}"
regular_key = json_start + "(.*?)" + json_end
```

	def get_json():
    f = open("疫情数据.txt", "r", encoding="utf-8")
    f_content = f.read()
    f.close()
    json_start = "try { window.getAreaStat = "
    json_end = "}catch\(e\){}"

    regular_key = json_start + "(.*?)" + json_end
    # 参数rs.S可以无视换行符，将所有文本视作一个整体进行匹配
    re_content = re.search(regular_key, f_content, re.S)
    # group()用于获取正则匹配后的字符串
    content = re_content.group()

    # 去除json字符串的前后关键词
    content = content.replace(json_start, '')
    # 尾巴要去掉转义符号
    json_end = "}catch(e){}"
    content = content.replace(json_end, '')

    print(content)
    return content
	json_content = get_json()
	browser.quit()
```


# 三、心得体会

实在太难了，之前没有学习过爬虫，用一些自学的东西来爬国家卫健委实在是太困难了，搞了两天没有成果，只能糊弄出来一个博客了，真的没办法了。

